# Automatic Image Captioning
This repository contains implementation of an *Automatic Image Captioning* algorithm, done as a part of Computer Vision(CSE-578) course at [IIIT Hyderabad](https://www.iiit.ac.in/) instructed by [Prof. Anoop Namboodiri](https://faculty.iiit.ac.in/~anoop/) in spring-2021. Our work has been inspired by [Show, Attend and Tell: Neural Image Caption Generation with Visual Attention](https://arxiv.org/abs/1502.03044), one of the seminal papers in the field of image captioning.

# Running the Code
- The files can be found in src folder
- To reproduce the resutls, run ```evaluating_examples.ipynb``` after installing the necessary libraries (list of libraries can be viewed in the first cell of the notebook) 
- To run the full code including training data, run ```fullcode.ipynb``` after installing the necessary libraries (list of libraries can be viewed in the first cell of the notebook) 

# Training the model
- Training the model requires extensive GPU resources. It is suggested to run the given code for at least 30 epochs (Ideally even more)
- In order to train the model it is suggested to use Kaggle or some other platform (Google Colab may not be suitable due to 12-hour runtime reset limit)

# Downloading the pre-trained model
- Download the checkpoints folder from [here](https://iiitaphyd-my.sharepoint.com/:f:/g/personal/abhishek_shah_students_iiit_ac_in/EscWhbR5ZwZAoPy6Ar5pPE8BQBNSUuI7UIEaOwn_OSmyZg?e=GAYNWX
) and place it in the src folder

# Team Members
This work has been done by [Abhishek Shah](https://github.com/AbhishekShah1709), [Amogh Tiwari](https://github.com/amoghtiwari/), [Tirth Upadhayaya](https://github.com/tirth7777777) and [Sai Tanmay Anand Reddy Chakkerra](https://github.com/starc52). 

# To Do
- Add a license.
- Add virtual environment details
